diff --git a/Cargo.lock b/Cargo.lock
index 622a808..26c75a7 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -1237,10 +1237,12 @@ dependencies = [
  "log",
  "parity-scale-codec",
  "scale-info",
+ "serde",
  "sp-consensus-aura",
  "sp-core",
  "sp-io",
  "sp-runtime",
+ "sp-std 14.0.0 (git+https://github.com/paritytech/polkadot-sdk?branch=release-polkadot-v1.9.0)",
 ]
 
 [[package]]
diff --git a/node/build.rs b/node/build.rs
index e3bfe31..f9d839f 100644
--- a/node/build.rs
+++ b/node/build.rs
@@ -1,7 +1,7 @@
 use substrate_build_script_utils::{generate_cargo_keys, rerun_if_git_head_changed};
 
 fn main() {
-	generate_cargo_keys();
+    generate_cargo_keys();
 
-	rerun_if_git_head_changed();
+    rerun_if_git_head_changed();
 }
diff --git a/node/src/benchmarking.rs b/node/src/benchmarking.rs
index 6b273e6..d4386cc 100644
--- a/node/src/benchmarking.rs
+++ b/node/src/benchmarking.rs
@@ -29,8 +29,8 @@ use sp_core::{ecdsa, Pair};
 use sp_inherents::{InherentData, InherentDataProvider};
 use sp_runtime::{generic::Era, OpaqueExtrinsic, SaturatedConversion};
 // Frontier
-use fp_account::AccountId20;
 use aya_runtime::{self as runtime, AccountId, Balance, BalancesCall, SystemCall};
+use fp_account::AccountId20;
 
 use crate::client::Client;
 
@@ -38,154 +38,154 @@ use crate::client::Client;
 ///
 /// Note: Should only be used for benchmarking.
 pub struct RemarkBuilder {
-	client: Arc<Client>,
+    client: Arc<Client>,
 }
 
 impl RemarkBuilder {
-	/// Creates a new [`Self`] from the given client.
-	pub fn new(client: Arc<Client>) -> Self {
-		Self { client }
-	}
+    /// Creates a new [`Self`] from the given client.
+    pub fn new(client: Arc<Client>) -> Self {
+        Self { client }
+    }
 }
 
 impl frame_benchmarking_cli::ExtrinsicBuilder for RemarkBuilder {
-	fn pallet(&self) -> &str {
-		"system"
-	}
-
-	fn extrinsic(&self) -> &str {
-		"remark"
-	}
-
-	fn build(&self, nonce: u32) -> std::result::Result<OpaqueExtrinsic, &'static str> {
-		let acc = ecdsa::Pair::from_string("//Bob", None).expect("static values are valid; qed");
-		let extrinsic: OpaqueExtrinsic = create_benchmark_extrinsic(
-			self.client.as_ref(),
-			acc,
-			SystemCall::remark { remark: vec![] }.into(),
-			nonce,
-		)
-		.into();
-
-		Ok(extrinsic)
-	}
+    fn pallet(&self) -> &str {
+        "system"
+    }
+
+    fn extrinsic(&self) -> &str {
+        "remark"
+    }
+
+    fn build(&self, nonce: u32) -> std::result::Result<OpaqueExtrinsic, &'static str> {
+        let acc = ecdsa::Pair::from_string("//Bob", None).expect("static values are valid; qed");
+        let extrinsic: OpaqueExtrinsic = create_benchmark_extrinsic(
+            self.client.as_ref(),
+            acc,
+            SystemCall::remark { remark: vec![] }.into(),
+            nonce,
+        )
+        .into();
+
+        Ok(extrinsic)
+    }
 }
 
 /// Generates `Balances::TransferKeepAlive` extrinsics for the benchmarks.
 ///
 /// Note: Should only be used for benchmarking.
 pub struct TransferKeepAliveBuilder {
-	client: Arc<Client>,
-	dest: AccountId,
-	value: Balance,
+    client: Arc<Client>,
+    dest: AccountId,
+    value: Balance,
 }
 
 impl TransferKeepAliveBuilder {
-	/// Creates a new [`Self`] from the given client.
-	pub fn new(client: Arc<Client>, dest: AccountId, value: Balance) -> Self {
-		Self {
-			client,
-			dest,
-			value,
-		}
-	}
+    /// Creates a new [`Self`] from the given client.
+    pub fn new(client: Arc<Client>, dest: AccountId, value: Balance) -> Self {
+        Self {
+            client,
+            dest,
+            value,
+        }
+    }
 }
 
 impl frame_benchmarking_cli::ExtrinsicBuilder for TransferKeepAliveBuilder {
-	fn pallet(&self) -> &str {
-		"balances"
-	}
-
-	fn extrinsic(&self) -> &str {
-		"transfer_keep_alive"
-	}
-
-	fn build(&self, nonce: u32) -> std::result::Result<OpaqueExtrinsic, &'static str> {
-		let acc = ecdsa::Pair::from_string("//Bob", None).expect("static values are valid; qed");
-		let extrinsic: OpaqueExtrinsic = create_benchmark_extrinsic(
-			self.client.as_ref(),
-			acc,
-			BalancesCall::transfer_keep_alive {
-				dest: self.dest,
-				value: self.value,
-			}
-			.into(),
-			nonce,
-		)
-		.into();
-
-		Ok(extrinsic)
-	}
+    fn pallet(&self) -> &str {
+        "balances"
+    }
+
+    fn extrinsic(&self) -> &str {
+        "transfer_keep_alive"
+    }
+
+    fn build(&self, nonce: u32) -> std::result::Result<OpaqueExtrinsic, &'static str> {
+        let acc = ecdsa::Pair::from_string("//Bob", None).expect("static values are valid; qed");
+        let extrinsic: OpaqueExtrinsic = create_benchmark_extrinsic(
+            self.client.as_ref(),
+            acc,
+            BalancesCall::transfer_keep_alive {
+                dest: self.dest,
+                value: self.value,
+            }
+            .into(),
+            nonce,
+        )
+        .into();
+
+        Ok(extrinsic)
+    }
 }
 
 /// Create a transaction using the given `call`.
 ///
 /// Note: Should only be used for benchmarking.
 pub fn create_benchmark_extrinsic(
-	client: &Client,
-	sender: ecdsa::Pair,
-	call: runtime::RuntimeCall,
-	nonce: u32,
+    client: &Client,
+    sender: ecdsa::Pair,
+    call: runtime::RuntimeCall,
+    nonce: u32,
 ) -> runtime::UncheckedExtrinsic {
-	let genesis_hash = client
-		.block_hash(0)
-		.ok()
-		.flatten()
-		.expect("Genesis block exists; qed");
-	let best_hash = client.chain_info().best_hash;
-	let best_block = client.chain_info().best_number;
-
-	let period = runtime::BlockHashCount::get()
-		.checked_next_power_of_two()
-		.map(|c| c / 2)
-		.unwrap_or(2) as u64;
-	let extra: runtime::SignedExtra = (
-		frame_system::CheckNonZeroSender::<runtime::Runtime>::new(),
-		frame_system::CheckSpecVersion::<runtime::Runtime>::new(),
-		frame_system::CheckTxVersion::<runtime::Runtime>::new(),
-		frame_system::CheckGenesis::<runtime::Runtime>::new(),
-		frame_system::CheckMortality::<runtime::Runtime>::from(Era::mortal(
-			period,
-			best_block.saturated_into(),
-		)),
-		frame_system::CheckNonce::<runtime::Runtime>::from(nonce),
-		frame_system::CheckWeight::<runtime::Runtime>::new(),
-		pallet_transaction_payment::ChargeTransactionPayment::<runtime::Runtime>::from(0),
-	);
-
-	let raw_payload = runtime::SignedPayload::from_raw(
-		call.clone(),
-		extra.clone(),
-		(
-			(),
-			runtime::VERSION.spec_version,
-			runtime::VERSION.transaction_version,
-			genesis_hash,
-			best_hash,
-			(),
-			(),
-			(),
-		),
-	);
-	let signature = raw_payload.using_encoded(|e| sender.sign(e));
-
-	runtime::UncheckedExtrinsic::new_signed(
-		call,
-		AccountId20::from(sender.public()),
-		runtime::Signature::new(signature),
-		extra,
-	)
+    let genesis_hash = client
+        .block_hash(0)
+        .ok()
+        .flatten()
+        .expect("Genesis block exists; qed");
+    let best_hash = client.chain_info().best_hash;
+    let best_block = client.chain_info().best_number;
+
+    let period = runtime::BlockHashCount::get()
+        .checked_next_power_of_two()
+        .map(|c| c / 2)
+        .unwrap_or(2) as u64;
+    let extra: runtime::SignedExtra = (
+        frame_system::CheckNonZeroSender::<runtime::Runtime>::new(),
+        frame_system::CheckSpecVersion::<runtime::Runtime>::new(),
+        frame_system::CheckTxVersion::<runtime::Runtime>::new(),
+        frame_system::CheckGenesis::<runtime::Runtime>::new(),
+        frame_system::CheckMortality::<runtime::Runtime>::from(Era::mortal(
+            period,
+            best_block.saturated_into(),
+        )),
+        frame_system::CheckNonce::<runtime::Runtime>::from(nonce),
+        frame_system::CheckWeight::<runtime::Runtime>::new(),
+        pallet_transaction_payment::ChargeTransactionPayment::<runtime::Runtime>::from(0),
+    );
+
+    let raw_payload = runtime::SignedPayload::from_raw(
+        call.clone(),
+        extra.clone(),
+        (
+            (),
+            runtime::VERSION.spec_version,
+            runtime::VERSION.transaction_version,
+            genesis_hash,
+            best_hash,
+            (),
+            (),
+            (),
+        ),
+    );
+    let signature = raw_payload.using_encoded(|e| sender.sign(e));
+
+    runtime::UncheckedExtrinsic::new_signed(
+        call,
+        AccountId20::from(sender.public()),
+        runtime::Signature::new(signature),
+        extra,
+    )
 }
 
 /// Generates inherent data for the `benchmark overhead` command.
 ///
 /// Note: Should only be used for benchmarking.
 pub fn inherent_benchmark_data() -> Result<InherentData> {
-	let mut inherent_data = InherentData::new();
-	let d = Duration::from_millis(0);
-	let timestamp = sp_timestamp::InherentDataProvider::new(d.into());
+    let mut inherent_data = InherentData::new();
+    let d = Duration::from_millis(0);
+    let timestamp = sp_timestamp::InherentDataProvider::new(d.into());
 
-	futures::executor::block_on(timestamp.provide_inherent_data(&mut inherent_data))
-		.map_err(|e| format!("creating inherent data: {:?}", e))?;
-	Ok(inherent_data)
+    futures::executor::block_on(timestamp.provide_inherent_data(&mut inherent_data))
+        .map_err(|e| format!("creating inherent data: {:?}", e))?;
+    Ok(inherent_data)
 }
diff --git a/node/src/chain_spec.rs b/node/src/chain_spec.rs
index 48aceba..2b01229 100644
--- a/node/src/chain_spec.rs
+++ b/node/src/chain_spec.rs
@@ -6,14 +6,14 @@ use pallet_im_online::sr25519::AuthorityId as ImOnlineId;
 use sc_chain_spec::{ChainType, Properties};
 use sp_consensus_aura::sr25519::AuthorityId as AuraId;
 use sp_consensus_grandpa::AuthorityId as GrandpaId;
-use sp_core::{H160, Pair, Public, U256};
 #[allow(unused_imports)]
 use sp_core::ecdsa;
+use sp_core::{Pair, Public, H160, U256};
 use sp_runtime::traits::{IdentifyAccount, Verify};
 
 // Frontier
 use aya_runtime::{
-    AccountId, Balance, opaque::SessionKeys, RuntimeGenesisConfig, Signature, SS58Prefix,
+    opaque::SessionKeys, AccountId, Balance, RuntimeGenesisConfig, SS58Prefix, Signature,
     WASM_BINARY,
 };
 
@@ -54,7 +54,10 @@ fn session_keys(aura: AuraId, grandpa: GrandpaId, im_online: ImOnlineId) -> Sess
     }
 }
 
-pub fn authority_keys_from_seed(s: &str, a: AccountId) -> (AccountId, AuraId, GrandpaId, ImOnlineId) {
+pub fn authority_keys_from_seed(
+    s: &str,
+    a: AccountId,
+) -> (AccountId, AuraId, GrandpaId, ImOnlineId) {
     (
         a,
         get_from_seed::<AuraId>(s),
diff --git a/node/src/cli.rs b/node/src/cli.rs
index fcae8cf..f639b2a 100644
--- a/node/src/cli.rs
+++ b/node/src/cli.rs
@@ -3,66 +3,66 @@ use crate::service::EthConfiguration;
 /// Available Sealing methods.
 #[derive(Copy, Clone, Debug, Default, clap::ValueEnum)]
 pub enum Sealing {
-	/// Seal using rpc method.
-	#[default]
-	Manual,
-	/// Seal when transaction is executed.
-	Instant,
+    /// Seal using rpc method.
+    #[default]
+    Manual,
+    /// Seal when transaction is executed.
+    Instant,
 }
 
 #[derive(Debug, clap::Parser)]
 pub struct Cli {
-	#[command(subcommand)]
-	pub subcommand: Option<Subcommand>,
+    #[command(subcommand)]
+    pub subcommand: Option<Subcommand>,
 
-	#[allow(missing_docs)]
-	#[command(flatten)]
-	pub run: sc_cli::RunCmd,
+    #[allow(missing_docs)]
+    #[command(flatten)]
+    pub run: sc_cli::RunCmd,
 
-	/// Choose sealing method.
-	#[arg(long, value_enum, ignore_case = true)]
-	pub sealing: Option<Sealing>,
+    /// Choose sealing method.
+    #[arg(long, value_enum, ignore_case = true)]
+    pub sealing: Option<Sealing>,
 
-	#[command(flatten)]
-	pub eth: EthConfiguration,
+    #[command(flatten)]
+    pub eth: EthConfiguration,
 }
 
 #[derive(Debug, clap::Subcommand)]
 pub enum Subcommand {
-	/// Key management cli utilities
-	#[command(subcommand)]
-	Key(sc_cli::KeySubcommand),
+    /// Key management cli utilities
+    #[command(subcommand)]
+    Key(sc_cli::KeySubcommand),
 
-	/// Build a chain specification.
-	BuildSpec(sc_cli::BuildSpecCmd),
+    /// Build a chain specification.
+    BuildSpec(sc_cli::BuildSpecCmd),
 
-	/// Validate blocks.
-	CheckBlock(sc_cli::CheckBlockCmd),
+    /// Validate blocks.
+    CheckBlock(sc_cli::CheckBlockCmd),
 
-	/// Export blocks.
-	ExportBlocks(sc_cli::ExportBlocksCmd),
+    /// Export blocks.
+    ExportBlocks(sc_cli::ExportBlocksCmd),
 
-	/// Export the state of a given block into a chain spec.
-	ExportState(sc_cli::ExportStateCmd),
+    /// Export the state of a given block into a chain spec.
+    ExportState(sc_cli::ExportStateCmd),
 
-	/// Import blocks.
-	ImportBlocks(sc_cli::ImportBlocksCmd),
+    /// Import blocks.
+    ImportBlocks(sc_cli::ImportBlocksCmd),
 
-	/// Remove the whole chain.
-	PurgeChain(sc_cli::PurgeChainCmd),
+    /// Remove the whole chain.
+    PurgeChain(sc_cli::PurgeChainCmd),
 
-	/// Revert the chain to a previous state.
-	Revert(sc_cli::RevertCmd),
+    /// Revert the chain to a previous state.
+    Revert(sc_cli::RevertCmd),
 
-	/// Sub-commands concerned with benchmarking.
-	#[cfg(feature = "runtime-benchmarks")]
-	#[command(subcommand)]
-	Benchmark(frame_benchmarking_cli::BenchmarkCmd),
+    /// Sub-commands concerned with benchmarking.
+    #[cfg(feature = "runtime-benchmarks")]
+    #[command(subcommand)]
+    Benchmark(frame_benchmarking_cli::BenchmarkCmd),
 
-	/// Sub-commands concerned with benchmarking.
-	#[cfg(not(feature = "runtime-benchmarks"))]
-	Benchmark,
+    /// Sub-commands concerned with benchmarking.
+    #[cfg(not(feature = "runtime-benchmarks"))]
+    Benchmark,
 
-	/// Db meta columns information.
-	FrontierDb(fc_cli::FrontierDbCmd),
+    /// Db meta columns information.
+    FrontierDb(fc_cli::FrontierDbCmd),
 }
diff --git a/node/src/client.rs b/node/src/client.rs
index b57b173..187f35d 100644
--- a/node/src/client.rs
+++ b/node/src/client.rs
@@ -10,7 +10,7 @@ use crate::eth::EthCompatRuntimeApiCollection;
 pub type FullBackend = sc_service::TFullBackend<Block>;
 /// Full client.
 pub type FullClient<RuntimeApi, Executor> =
-	sc_service::TFullClient<Block, RuntimeApi, NativeElseWasmExecutor<Executor>>;
+    sc_service::TFullClient<Block, RuntimeApi, NativeElseWasmExecutor<Executor>>;
 
 pub type Client = FullClient<aya_runtime::RuntimeApi, TemplateRuntimeExecutor>;
 
@@ -23,55 +23,55 @@ pub type HostFunctions = ();
 
 pub struct TemplateRuntimeExecutor;
 impl NativeExecutionDispatch for TemplateRuntimeExecutor {
-	type ExtendHostFunctions = HostFunctions;
+    type ExtendHostFunctions = HostFunctions;
 
-	fn dispatch(method: &str, data: &[u8]) -> Option<Vec<u8>> {
-		aya_runtime::api::dispatch(method, data)
-	}
+    fn dispatch(method: &str, data: &[u8]) -> Option<Vec<u8>> {
+        aya_runtime::api::dispatch(method, data)
+    }
 
-	fn native_version() -> NativeVersion {
-		aya_runtime::native_version()
-	}
+    fn native_version() -> NativeVersion {
+        aya_runtime::native_version()
+    }
 }
 
 /// A set of APIs that every runtimes must implement.
 pub trait BaseRuntimeApiCollection:
-	sp_api::ApiExt<Block>
-	+ sp_api::Metadata<Block>
-	+ sp_block_builder::BlockBuilder<Block>
-	+ sp_offchain::OffchainWorkerApi<Block>
-	+ sp_session::SessionKeys<Block>
-	+ sp_transaction_pool::runtime_api::TaggedTransactionQueue<Block>
+    sp_api::ApiExt<Block>
+    + sp_api::Metadata<Block>
+    + sp_block_builder::BlockBuilder<Block>
+    + sp_offchain::OffchainWorkerApi<Block>
+    + sp_session::SessionKeys<Block>
+    + sp_transaction_pool::runtime_api::TaggedTransactionQueue<Block>
 {
 }
 
 impl<Api> BaseRuntimeApiCollection for Api where
-	Api: sp_api::ApiExt<Block>
-		+ sp_api::Metadata<Block>
-		+ sp_block_builder::BlockBuilder<Block>
-		+ sp_offchain::OffchainWorkerApi<Block>
-		+ sp_session::SessionKeys<Block>
-		+ sp_transaction_pool::runtime_api::TaggedTransactionQueue<Block>
+    Api: sp_api::ApiExt<Block>
+        + sp_api::Metadata<Block>
+        + sp_block_builder::BlockBuilder<Block>
+        + sp_offchain::OffchainWorkerApi<Block>
+        + sp_session::SessionKeys<Block>
+        + sp_transaction_pool::runtime_api::TaggedTransactionQueue<Block>
 {
 }
 
 /// A set of APIs that template runtime must implement.
 pub trait RuntimeApiCollection:
-	BaseRuntimeApiCollection
-	+ EthCompatRuntimeApiCollection
-	+ sp_consensus_aura::AuraApi<Block, AuraId>
-	+ sp_consensus_grandpa::GrandpaApi<Block>
-	+ frame_system_rpc_runtime_api::AccountNonceApi<Block, AccountId, Nonce>
-	+ pallet_transaction_payment_rpc_runtime_api::TransactionPaymentApi<Block, Balance>
+    BaseRuntimeApiCollection
+    + EthCompatRuntimeApiCollection
+    + sp_consensus_aura::AuraApi<Block, AuraId>
+    + sp_consensus_grandpa::GrandpaApi<Block>
+    + frame_system_rpc_runtime_api::AccountNonceApi<Block, AccountId, Nonce>
+    + pallet_transaction_payment_rpc_runtime_api::TransactionPaymentApi<Block, Balance>
 {
 }
 
 impl<Api> RuntimeApiCollection for Api where
-	Api: BaseRuntimeApiCollection
-		+ EthCompatRuntimeApiCollection
-		+ sp_consensus_aura::AuraApi<Block, AuraId>
-		+ sp_consensus_grandpa::GrandpaApi<Block>
-		+ frame_system_rpc_runtime_api::AccountNonceApi<Block, AccountId, Nonce>
-		+ pallet_transaction_payment_rpc_runtime_api::TransactionPaymentApi<Block, Balance>
+    Api: BaseRuntimeApiCollection
+        + EthCompatRuntimeApiCollection
+        + sp_consensus_aura::AuraApi<Block, AuraId>
+        + sp_consensus_grandpa::GrandpaApi<Block>
+        + frame_system_rpc_runtime_api::AccountNonceApi<Block, AccountId, Nonce>
+        + pallet_transaction_payment_rpc_runtime_api::TransactionPaymentApi<Block, Balance>
 {
 }
diff --git a/node/src/command.rs b/node/src/command.rs
index b60277b..9aef14d 100644
--- a/node/src/command.rs
+++ b/node/src/command.rs
@@ -23,232 +23,232 @@ use sc_service::DatabaseSource;
 use fc_db::kv::frontier_database_dir;
 
 use crate::{
-	chain_spec,
-	cli::{Cli, Subcommand},
-	service::{self, db_config_dir},
+    chain_spec,
+    cli::{Cli, Subcommand},
+    service::{self, db_config_dir},
 };
 
 #[cfg(feature = "runtime-benchmarks")]
 use crate::chain_spec::get_account_id_from_seed;
 
 impl SubstrateCli for Cli {
-	fn impl_name() -> String {
-		"AyA Node".into()
-	}
-
-	fn impl_version() -> String {
-		env!("SUBSTRATE_CLI_IMPL_VERSION").into()
-	}
-
-	fn description() -> String {
-		env!("CARGO_PKG_DESCRIPTION").into()
-	}
-
-	fn author() -> String {
-		env!("CARGO_PKG_AUTHORS").into()
-	}
-
-	fn support_url() -> String {
-		"support.anonymous.an".into()
-	}
-
-	fn copyright_start_year() -> i32 {
-		2021
-	}
-
-	fn load_spec(&self, id: &str) -> Result<Box<dyn ChainSpec>, String> {
-		Ok(match id {
-			"dev" => {
-				let enable_manual_seal = self.sealing.map(|_| true).unwrap_or_default();
-				Box::new(chain_spec::development_config(enable_manual_seal))
-			}
-			"" | "local" => Box::new(chain_spec::local_testnet_config()),
-			path => Box::new(chain_spec::ChainSpec::from_json_file(
-				std::path::PathBuf::from(path),
-			)?),
-		})
-	}
+    fn impl_name() -> String {
+        "AyA Node".into()
+    }
+
+    fn impl_version() -> String {
+        env!("SUBSTRATE_CLI_IMPL_VERSION").into()
+    }
+
+    fn description() -> String {
+        env!("CARGO_PKG_DESCRIPTION").into()
+    }
+
+    fn author() -> String {
+        env!("CARGO_PKG_AUTHORS").into()
+    }
+
+    fn support_url() -> String {
+        "support.anonymous.an".into()
+    }
+
+    fn copyright_start_year() -> i32 {
+        2021
+    }
+
+    fn load_spec(&self, id: &str) -> Result<Box<dyn ChainSpec>, String> {
+        Ok(match id {
+            "dev" => {
+                let enable_manual_seal = self.sealing.map(|_| true).unwrap_or_default();
+                Box::new(chain_spec::development_config(enable_manual_seal))
+            }
+            "" | "local" => Box::new(chain_spec::local_testnet_config()),
+            path => Box::new(chain_spec::ChainSpec::from_json_file(
+                std::path::PathBuf::from(path),
+            )?),
+        })
+    }
 }
 
 /// Parse and run command line arguments
 pub fn run() -> sc_cli::Result<()> {
-	let cli = Cli::from_args();
-
-	match &cli.subcommand {
-		Some(Subcommand::Key(cmd)) => cmd.run(&cli),
-		Some(Subcommand::BuildSpec(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.sync_run(|config| cmd.run(config.chain_spec, config.network))
-		}
-		Some(Subcommand::CheckBlock(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.async_run(|mut config| {
-				let (client, _, import_queue, task_manager, _) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				Ok((cmd.run(client, import_queue), task_manager))
-			})
-		}
-		Some(Subcommand::ExportBlocks(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.async_run(|mut config| {
-				let (client, _, _, task_manager, _) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				Ok((cmd.run(client, config.database), task_manager))
-			})
-		}
-		Some(Subcommand::ExportState(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.async_run(|mut config| {
-				let (client, _, _, task_manager, _) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				Ok((cmd.run(client, config.chain_spec), task_manager))
-			})
-		}
-		Some(Subcommand::ImportBlocks(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.async_run(|mut config| {
-				let (client, _, import_queue, task_manager, _) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				Ok((cmd.run(client, import_queue), task_manager))
-			})
-		}
-		Some(Subcommand::PurgeChain(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.sync_run(|config| {
-				// Remove Frontier offchain db
-				let db_config_dir = db_config_dir(&config);
-				match cli.eth.frontier_backend_type {
-					crate::eth::BackendType::KeyValue => {
-						let frontier_database_config = match config.database {
-							DatabaseSource::RocksDb { .. } => DatabaseSource::RocksDb {
-								path: frontier_database_dir(&db_config_dir, "db"),
-								cache_size: 0,
-							},
-							DatabaseSource::ParityDb { .. } => DatabaseSource::ParityDb {
-								path: frontier_database_dir(&db_config_dir, "paritydb"),
-							},
-							_ => {
-								return Err(format!(
-									"Cannot purge `{:?}` database",
-									config.database
-								)
-								.into())
-							}
-						};
-						cmd.run(frontier_database_config)?;
-					}
-					crate::eth::BackendType::Sql => {
-						let db_path = db_config_dir.join("sql");
-						match std::fs::remove_dir_all(&db_path) {
-							Ok(_) => {
-								println!("{:?} removed.", &db_path);
-							}
-							Err(ref err) if err.kind() == std::io::ErrorKind::NotFound => {
-								eprintln!("{:?} did not exist.", &db_path);
-							}
-							Err(err) => {
-								return Err(format!(
-									"Cannot purge `{:?}` database: {:?}",
-									db_path, err,
-								)
-								.into())
-							}
-						};
-					}
-				};
-				cmd.run(config.database)
-			})
-		}
-		Some(Subcommand::Revert(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.async_run(|mut config| {
-				let (client, backend, _, task_manager, _) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				let aux_revert = Box::new(move |client, _, blocks| {
-					sc_consensus_grandpa::revert(client, blocks)?;
-					Ok(())
-				});
-				Ok((cmd.run(client, backend, Some(aux_revert)), task_manager))
-			})
-		}
-		#[cfg(feature = "runtime-benchmarks")]
-		Some(Subcommand::Benchmark(cmd)) => {
-			use crate::benchmarking::{
-				inherent_benchmark_data, RemarkBuilder, TransferKeepAliveBuilder,
-			};
-			use frame_benchmarking_cli::{
-				BenchmarkCmd, ExtrinsicFactory, SUBSTRATE_REFERENCE_HARDWARE,
-			};
-			use aya_runtime::{ExistentialDeposit, Hashing};
-
-			let runner = cli.create_runner(cmd)?;
-			match cmd {
-				BenchmarkCmd::Pallet(cmd) => {
-					runner.sync_run(|config| cmd.run::<Hashing, ()>(config))
-				}
-				BenchmarkCmd::Block(cmd) => runner.sync_run(|mut config| {
-					let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
-					cmd.run(client)
-				}),
-				BenchmarkCmd::Storage(cmd) => runner.sync_run(|mut config| {
-					let (client, backend, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
-					let db = backend.expose_db();
-					let storage = backend.expose_storage();
-					cmd.run(config, client, db, storage)
-				}),
-				BenchmarkCmd::Overhead(cmd) => runner.sync_run(|mut config| {
-					let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
-					let ext_builder = RemarkBuilder::new(client.clone());
-					cmd.run(
-						config,
-						client,
-						inherent_benchmark_data()?,
-						Vec::new(),
-						&ext_builder,
-					)
-				}),
-				BenchmarkCmd::Extrinsic(cmd) => runner.sync_run(|mut config| {
-					let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
-					// Register the *Remark* and *TKA* builders.
-					let ext_factory = ExtrinsicFactory(vec![
-						Box::new(RemarkBuilder::new(client.clone())),
-						Box::new(TransferKeepAliveBuilder::new(
-							client.clone(),
-							get_account_id_from_seed::<sp_core::ecdsa::Public>("Alice"),
-							ExistentialDeposit::get(),
-						)),
-					]);
-
-					cmd.run(client, inherent_benchmark_data()?, Vec::new(), &ext_factory)
-				}),
-				BenchmarkCmd::Machine(cmd) => {
-					runner.sync_run(|config| cmd.run(&config, SUBSTRATE_REFERENCE_HARDWARE.clone()))
-				}
-			}
-		}
-		#[cfg(not(feature = "runtime-benchmarks"))]
-		Some(Subcommand::Benchmark) => Err("Benchmarking wasn't enabled when building the node. \
+    let cli = Cli::from_args();
+
+    match &cli.subcommand {
+        Some(Subcommand::Key(cmd)) => cmd.run(&cli),
+        Some(Subcommand::BuildSpec(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.sync_run(|config| cmd.run(config.chain_spec, config.network))
+        }
+        Some(Subcommand::CheckBlock(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.async_run(|mut config| {
+                let (client, _, import_queue, task_manager, _) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                Ok((cmd.run(client, import_queue), task_manager))
+            })
+        }
+        Some(Subcommand::ExportBlocks(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.async_run(|mut config| {
+                let (client, _, _, task_manager, _) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                Ok((cmd.run(client, config.database), task_manager))
+            })
+        }
+        Some(Subcommand::ExportState(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.async_run(|mut config| {
+                let (client, _, _, task_manager, _) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                Ok((cmd.run(client, config.chain_spec), task_manager))
+            })
+        }
+        Some(Subcommand::ImportBlocks(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.async_run(|mut config| {
+                let (client, _, import_queue, task_manager, _) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                Ok((cmd.run(client, import_queue), task_manager))
+            })
+        }
+        Some(Subcommand::PurgeChain(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.sync_run(|config| {
+                // Remove Frontier offchain db
+                let db_config_dir = db_config_dir(&config);
+                match cli.eth.frontier_backend_type {
+                    crate::eth::BackendType::KeyValue => {
+                        let frontier_database_config = match config.database {
+                            DatabaseSource::RocksDb { .. } => DatabaseSource::RocksDb {
+                                path: frontier_database_dir(&db_config_dir, "db"),
+                                cache_size: 0,
+                            },
+                            DatabaseSource::ParityDb { .. } => DatabaseSource::ParityDb {
+                                path: frontier_database_dir(&db_config_dir, "paritydb"),
+                            },
+                            _ => {
+                                return Err(format!(
+                                    "Cannot purge `{:?}` database",
+                                    config.database
+                                )
+                                .into())
+                            }
+                        };
+                        cmd.run(frontier_database_config)?;
+                    }
+                    crate::eth::BackendType::Sql => {
+                        let db_path = db_config_dir.join("sql");
+                        match std::fs::remove_dir_all(&db_path) {
+                            Ok(_) => {
+                                println!("{:?} removed.", &db_path);
+                            }
+                            Err(ref err) if err.kind() == std::io::ErrorKind::NotFound => {
+                                eprintln!("{:?} did not exist.", &db_path);
+                            }
+                            Err(err) => {
+                                return Err(format!(
+                                    "Cannot purge `{:?}` database: {:?}",
+                                    db_path, err,
+                                )
+                                .into())
+                            }
+                        };
+                    }
+                };
+                cmd.run(config.database)
+            })
+        }
+        Some(Subcommand::Revert(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.async_run(|mut config| {
+                let (client, backend, _, task_manager, _) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                let aux_revert = Box::new(move |client, _, blocks| {
+                    sc_consensus_grandpa::revert(client, blocks)?;
+                    Ok(())
+                });
+                Ok((cmd.run(client, backend, Some(aux_revert)), task_manager))
+            })
+        }
+        #[cfg(feature = "runtime-benchmarks")]
+        Some(Subcommand::Benchmark(cmd)) => {
+            use crate::benchmarking::{
+                inherent_benchmark_data, RemarkBuilder, TransferKeepAliveBuilder,
+            };
+            use aya_runtime::{ExistentialDeposit, Hashing};
+            use frame_benchmarking_cli::{
+                BenchmarkCmd, ExtrinsicFactory, SUBSTRATE_REFERENCE_HARDWARE,
+            };
+
+            let runner = cli.create_runner(cmd)?;
+            match cmd {
+                BenchmarkCmd::Pallet(cmd) => {
+                    runner.sync_run(|config| cmd.run::<Hashing, ()>(config))
+                }
+                BenchmarkCmd::Block(cmd) => runner.sync_run(|mut config| {
+                    let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
+                    cmd.run(client)
+                }),
+                BenchmarkCmd::Storage(cmd) => runner.sync_run(|mut config| {
+                    let (client, backend, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
+                    let db = backend.expose_db();
+                    let storage = backend.expose_storage();
+                    cmd.run(config, client, db, storage)
+                }),
+                BenchmarkCmd::Overhead(cmd) => runner.sync_run(|mut config| {
+                    let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
+                    let ext_builder = RemarkBuilder::new(client.clone());
+                    cmd.run(
+                        config,
+                        client,
+                        inherent_benchmark_data()?,
+                        Vec::new(),
+                        &ext_builder,
+                    )
+                }),
+                BenchmarkCmd::Extrinsic(cmd) => runner.sync_run(|mut config| {
+                    let (client, _, _, _, _) = service::new_chain_ops(&mut config, &cli.eth)?;
+                    // Register the *Remark* and *TKA* builders.
+                    let ext_factory = ExtrinsicFactory(vec![
+                        Box::new(RemarkBuilder::new(client.clone())),
+                        Box::new(TransferKeepAliveBuilder::new(
+                            client.clone(),
+                            get_account_id_from_seed::<sp_core::ecdsa::Public>("Alice"),
+                            ExistentialDeposit::get(),
+                        )),
+                    ]);
+
+                    cmd.run(client, inherent_benchmark_data()?, Vec::new(), &ext_factory)
+                }),
+                BenchmarkCmd::Machine(cmd) => {
+                    runner.sync_run(|config| cmd.run(&config, SUBSTRATE_REFERENCE_HARDWARE.clone()))
+                }
+            }
+        }
+        #[cfg(not(feature = "runtime-benchmarks"))]
+        Some(Subcommand::Benchmark) => Err("Benchmarking wasn't enabled when building the node. \
 			You can enable it with `--features runtime-benchmarks`."
-			.into()),
-		Some(Subcommand::FrontierDb(cmd)) => {
-			let runner = cli.create_runner(cmd)?;
-			runner.sync_run(|mut config| {
-				let (client, _, _, _, frontier_backend) =
-					service::new_chain_ops(&mut config, &cli.eth)?;
-				let frontier_backend = match frontier_backend {
-					fc_db::Backend::KeyValue(kv) => std::sync::Arc::new(kv),
-					_ => panic!("Only fc_db::Backend::KeyValue supported"),
-				};
-				cmd.run(client, frontier_backend)
-			})
-		}
-		None => {
-			let runner = cli.create_runner(&cli.run)?;
-			runner.run_node_until_exit(|config| async move {
-				service::build_full(config, cli.eth, cli.sealing)
-					.map_err(Into::into)
-					.await
-			})
-		}
-	}
+            .into()),
+        Some(Subcommand::FrontierDb(cmd)) => {
+            let runner = cli.create_runner(cmd)?;
+            runner.sync_run(|mut config| {
+                let (client, _, _, _, frontier_backend) =
+                    service::new_chain_ops(&mut config, &cli.eth)?;
+                let frontier_backend = match frontier_backend {
+                    fc_db::Backend::KeyValue(kv) => std::sync::Arc::new(kv),
+                    _ => panic!("Only fc_db::Backend::KeyValue supported"),
+                };
+                cmd.run(client, frontier_backend)
+            })
+        }
+        None => {
+            let runner = cli.create_runner(&cli.run)?;
+            runner.run_node_until_exit(|config| async move {
+                service::build_full(config, cli.eth, cli.sealing)
+                    .map_err(Into::into)
+                    .await
+            })
+        }
+    }
 }
diff --git a/node/src/eth.rs b/node/src/eth.rs
index e4998d2..aa220a7 100644
--- a/node/src/eth.rs
+++ b/node/src/eth.rs
@@ -1,8 +1,8 @@
 use std::{
-	collections::BTreeMap,
-	path::PathBuf,
-	sync::{Arc, Mutex},
-	time::Duration,
+    collections::BTreeMap,
+    path::PathBuf,
+    sync::{Arc, Mutex},
+    time::Duration,
 };
 
 use futures::{future, prelude::*};
@@ -25,187 +25,187 @@ use crate::client::{FullBackend, FullClient};
 pub type FrontierBackend = fc_db::Backend<Block>;
 
 pub fn db_config_dir(config: &Configuration) -> PathBuf {
-	config.base_path.config_dir(config.chain_spec.id())
+    config.base_path.config_dir(config.chain_spec.id())
 }
 
 /// Avalailable frontier backend types.
 #[derive(Debug, Copy, Clone, Default, clap::ValueEnum)]
 pub enum BackendType {
-	/// Either RocksDb or ParityDb as per inherited from the global backend settings.
-	#[default]
-	KeyValue,
-	/// Sql database with custom log indexing.
-	Sql,
+    /// Either RocksDb or ParityDb as per inherited from the global backend settings.
+    #[default]
+    KeyValue,
+    /// Sql database with custom log indexing.
+    Sql,
 }
 
 /// The ethereum-compatibility configuration used to run a node.
 #[derive(Clone, Debug, clap::Parser)]
 pub struct EthConfiguration {
-	/// Maximum number of logs in a query.
-	#[arg(long, default_value = "10000")]
-	pub max_past_logs: u32,
-
-	/// Maximum fee history cache size.
-	#[arg(long, default_value = "2048")]
-	pub fee_history_limit: u64,
-
-	#[arg(long)]
-	pub enable_dev_signer: bool,
-
-	/// The dynamic-fee pallet target gas price set by block author
-	#[arg(long, default_value = "1")]
-	pub target_gas_price: u64,
-
-	/// Maximum allowed gas limit will be `block.gas_limit * execute_gas_limit_multiplier`
-	/// when using eth_call/eth_estimateGas.
-	#[arg(long, default_value = "10")]
-	pub execute_gas_limit_multiplier: u64,
-
-	/// Size in bytes of the LRU cache for block data.
-	#[arg(long, default_value = "50")]
-	pub eth_log_block_cache: usize,
-
-	/// Size in bytes of the LRU cache for transactions statuses data.
-	#[arg(long, default_value = "50")]
-	pub eth_statuses_cache: usize,
-
-	/// Sets the frontier backend type (KeyValue or Sql)
-	#[arg(long, value_enum, ignore_case = true, default_value_t = BackendType::default())]
-	pub frontier_backend_type: BackendType,
-
-	// Sets the SQL backend's pool size.
-	#[arg(long, default_value = "100")]
-	pub frontier_sql_backend_pool_size: u32,
-
-	/// Sets the SQL backend's query timeout in number of VM ops.
-	#[arg(long, default_value = "10000000")]
-	pub frontier_sql_backend_num_ops_timeout: u32,
-
-	/// Sets the SQL backend's auxiliary thread limit.
-	#[arg(long, default_value = "4")]
-	pub frontier_sql_backend_thread_count: u32,
-
-	/// Sets the SQL backend's query timeout in number of VM ops.
-	/// Default value is 200MB.
-	#[arg(long, default_value = "209715200")]
-	pub frontier_sql_backend_cache_size: u64,
+    /// Maximum number of logs in a query.
+    #[arg(long, default_value = "10000")]
+    pub max_past_logs: u32,
+
+    /// Maximum fee history cache size.
+    #[arg(long, default_value = "2048")]
+    pub fee_history_limit: u64,
+
+    #[arg(long)]
+    pub enable_dev_signer: bool,
+
+    /// The dynamic-fee pallet target gas price set by block author
+    #[arg(long, default_value = "1")]
+    pub target_gas_price: u64,
+
+    /// Maximum allowed gas limit will be `block.gas_limit * execute_gas_limit_multiplier`
+    /// when using eth_call/eth_estimateGas.
+    #[arg(long, default_value = "10")]
+    pub execute_gas_limit_multiplier: u64,
+
+    /// Size in bytes of the LRU cache for block data.
+    #[arg(long, default_value = "50")]
+    pub eth_log_block_cache: usize,
+
+    /// Size in bytes of the LRU cache for transactions statuses data.
+    #[arg(long, default_value = "50")]
+    pub eth_statuses_cache: usize,
+
+    /// Sets the frontier backend type (KeyValue or Sql)
+    #[arg(long, value_enum, ignore_case = true, default_value_t = BackendType::default())]
+    pub frontier_backend_type: BackendType,
+
+    // Sets the SQL backend's pool size.
+    #[arg(long, default_value = "100")]
+    pub frontier_sql_backend_pool_size: u32,
+
+    /// Sets the SQL backend's query timeout in number of VM ops.
+    #[arg(long, default_value = "10000000")]
+    pub frontier_sql_backend_num_ops_timeout: u32,
+
+    /// Sets the SQL backend's auxiliary thread limit.
+    #[arg(long, default_value = "4")]
+    pub frontier_sql_backend_thread_count: u32,
+
+    /// Sets the SQL backend's query timeout in number of VM ops.
+    /// Default value is 200MB.
+    #[arg(long, default_value = "209715200")]
+    pub frontier_sql_backend_cache_size: u64,
 }
 
 pub struct FrontierPartialComponents {
-	pub filter_pool: Option<FilterPool>,
-	pub fee_history_cache: FeeHistoryCache,
-	pub fee_history_cache_limit: FeeHistoryCacheLimit,
+    pub filter_pool: Option<FilterPool>,
+    pub fee_history_cache: FeeHistoryCache,
+    pub fee_history_cache_limit: FeeHistoryCacheLimit,
 }
 
 pub fn new_frontier_partial(
-	config: &EthConfiguration,
+    config: &EthConfiguration,
 ) -> Result<FrontierPartialComponents, ServiceError> {
-	Ok(FrontierPartialComponents {
-		filter_pool: Some(Arc::new(Mutex::new(BTreeMap::new()))),
-		fee_history_cache: Arc::new(Mutex::new(BTreeMap::new())),
-		fee_history_cache_limit: config.fee_history_limit,
-	})
+    Ok(FrontierPartialComponents {
+        filter_pool: Some(Arc::new(Mutex::new(BTreeMap::new()))),
+        fee_history_cache: Arc::new(Mutex::new(BTreeMap::new())),
+        fee_history_cache_limit: config.fee_history_limit,
+    })
 }
 
 /// A set of APIs that ethereum-compatible runtimes must implement.
 pub trait EthCompatRuntimeApiCollection:
-	sp_api::ApiExt<Block>
-	+ fp_rpc::ConvertTransactionRuntimeApi<Block>
-	+ fp_rpc::EthereumRuntimeRPCApi<Block>
+    sp_api::ApiExt<Block>
+    + fp_rpc::ConvertTransactionRuntimeApi<Block>
+    + fp_rpc::EthereumRuntimeRPCApi<Block>
 {
 }
 
 impl<Api> EthCompatRuntimeApiCollection for Api where
-	Api: sp_api::ApiExt<Block>
-		+ fp_rpc::ConvertTransactionRuntimeApi<Block>
-		+ fp_rpc::EthereumRuntimeRPCApi<Block>
+    Api: sp_api::ApiExt<Block>
+        + fp_rpc::ConvertTransactionRuntimeApi<Block>
+        + fp_rpc::EthereumRuntimeRPCApi<Block>
 {
 }
 
 pub async fn spawn_frontier_tasks<RuntimeApi, Executor>(
-	task_manager: &TaskManager,
-	client: Arc<FullClient<RuntimeApi, Executor>>,
-	backend: Arc<FullBackend>,
-	frontier_backend: FrontierBackend,
-	filter_pool: Option<FilterPool>,
-	overrides: Arc<OverrideHandle<Block>>,
-	fee_history_cache: FeeHistoryCache,
-	fee_history_cache_limit: FeeHistoryCacheLimit,
-	sync: Arc<SyncingService<Block>>,
-	pubsub_notification_sinks: Arc<
-		fc_mapping_sync::EthereumBlockNotificationSinks<
-			fc_mapping_sync::EthereumBlockNotification<Block>,
-		>,
-	>,
+    task_manager: &TaskManager,
+    client: Arc<FullClient<RuntimeApi, Executor>>,
+    backend: Arc<FullBackend>,
+    frontier_backend: FrontierBackend,
+    filter_pool: Option<FilterPool>,
+    overrides: Arc<OverrideHandle<Block>>,
+    fee_history_cache: FeeHistoryCache,
+    fee_history_cache_limit: FeeHistoryCacheLimit,
+    sync: Arc<SyncingService<Block>>,
+    pubsub_notification_sinks: Arc<
+        fc_mapping_sync::EthereumBlockNotificationSinks<
+            fc_mapping_sync::EthereumBlockNotification<Block>,
+        >,
+    >,
 ) where
-	RuntimeApi: ConstructRuntimeApi<Block, FullClient<RuntimeApi, Executor>>,
-	RuntimeApi: Send + Sync + 'static,
-	RuntimeApi::RuntimeApi: EthCompatRuntimeApiCollection,
-	Executor: NativeExecutionDispatch + 'static,
+    RuntimeApi: ConstructRuntimeApi<Block, FullClient<RuntimeApi, Executor>>,
+    RuntimeApi: Send + Sync + 'static,
+    RuntimeApi::RuntimeApi: EthCompatRuntimeApiCollection,
+    Executor: NativeExecutionDispatch + 'static,
 {
-	// Spawn main mapping sync worker background task.
-	match frontier_backend {
-		fc_db::Backend::KeyValue(b) => {
-			task_manager.spawn_essential_handle().spawn(
-				"frontier-mapping-sync-worker",
-				Some("frontier"),
-				fc_mapping_sync::kv::MappingSyncWorker::new(
-					client.import_notification_stream(),
-					Duration::new(6, 0),
-					client.clone(),
-					backend,
-					overrides.clone(),
-					Arc::new(b),
-					3,
-					0,
-					fc_mapping_sync::SyncStrategy::Normal,
-					sync,
-					pubsub_notification_sinks,
-				)
-				.for_each(|()| future::ready(())),
-			);
-		}
-		fc_db::Backend::Sql(b) => {
-			task_manager.spawn_essential_handle().spawn_blocking(
-				"frontier-mapping-sync-worker",
-				Some("frontier"),
-				fc_mapping_sync::sql::SyncWorker::run(
-					client.clone(),
-					backend,
-					Arc::new(b),
-					client.import_notification_stream(),
-					fc_mapping_sync::sql::SyncWorkerConfig {
-						read_notification_timeout: Duration::from_secs(10),
-						check_indexed_blocks_interval: Duration::from_secs(60),
-					},
-					fc_mapping_sync::SyncStrategy::Parachain,
-					sync,
-					pubsub_notification_sinks,
-				),
-			);
-		}
-	}
-
-	// Spawn Frontier EthFilterApi maintenance task.
-	if let Some(filter_pool) = filter_pool {
-		// Each filter is allowed to stay in the pool for 100 blocks.
-		const FILTER_RETAIN_THRESHOLD: u64 = 100;
-		task_manager.spawn_essential_handle().spawn(
-			"frontier-filter-pool",
-			Some("frontier"),
-			EthTask::filter_pool_task(client.clone(), filter_pool, FILTER_RETAIN_THRESHOLD),
-		);
-	}
-
-	// Spawn Frontier FeeHistory cache maintenance task.
-	task_manager.spawn_essential_handle().spawn(
-		"frontier-fee-history",
-		Some("frontier"),
-		EthTask::fee_history_task(
-			client,
-			overrides,
-			fee_history_cache,
-			fee_history_cache_limit,
-		),
-	);
+    // Spawn main mapping sync worker background task.
+    match frontier_backend {
+        fc_db::Backend::KeyValue(b) => {
+            task_manager.spawn_essential_handle().spawn(
+                "frontier-mapping-sync-worker",
+                Some("frontier"),
+                fc_mapping_sync::kv::MappingSyncWorker::new(
+                    client.import_notification_stream(),
+                    Duration::new(6, 0),
+                    client.clone(),
+                    backend,
+                    overrides.clone(),
+                    Arc::new(b),
+                    3,
+                    0,
+                    fc_mapping_sync::SyncStrategy::Normal,
+                    sync,
+                    pubsub_notification_sinks,
+                )
+                .for_each(|()| future::ready(())),
+            );
+        }
+        fc_db::Backend::Sql(b) => {
+            task_manager.spawn_essential_handle().spawn_blocking(
+                "frontier-mapping-sync-worker",
+                Some("frontier"),
+                fc_mapping_sync::sql::SyncWorker::run(
+                    client.clone(),
+                    backend,
+                    Arc::new(b),
+                    client.import_notification_stream(),
+                    fc_mapping_sync::sql::SyncWorkerConfig {
+                        read_notification_timeout: Duration::from_secs(10),
+                        check_indexed_blocks_interval: Duration::from_secs(60),
+                    },
+                    fc_mapping_sync::SyncStrategy::Parachain,
+                    sync,
+                    pubsub_notification_sinks,
+                ),
+            );
+        }
+    }
+
+    // Spawn Frontier EthFilterApi maintenance task.
+    if let Some(filter_pool) = filter_pool {
+        // Each filter is allowed to stay in the pool for 100 blocks.
+        const FILTER_RETAIN_THRESHOLD: u64 = 100;
+        task_manager.spawn_essential_handle().spawn(
+            "frontier-filter-pool",
+            Some("frontier"),
+            EthTask::filter_pool_task(client.clone(), filter_pool, FILTER_RETAIN_THRESHOLD),
+        );
+    }
+
+    // Spawn Frontier FeeHistory cache maintenance task.
+    task_manager.spawn_essential_handle().spawn(
+        "frontier-fee-history",
+        Some("frontier"),
+        EthTask::fee_history_task(
+            client,
+            overrides,
+            fee_history_cache,
+            fee_history_cache_limit,
+        ),
+    );
 }
diff --git a/node/src/main.rs b/node/src/main.rs
index 0bb5dad..8e099f6 100644
--- a/node/src/main.rs
+++ b/node/src/main.rs
@@ -2,9 +2,9 @@
 
 #![warn(missing_docs)]
 #![allow(
-	clippy::type_complexity,
-	clippy::too_many_arguments,
-	clippy::large_enum_variant
+    clippy::type_complexity,
+    clippy::too_many_arguments,
+    clippy::large_enum_variant
 )]
 #![cfg_attr(feature = "runtime-benchmarks", warn(unused_crate_dependencies))]
 
@@ -19,5 +19,5 @@ mod rpc;
 mod service;
 
 fn main() -> sc_cli::Result<()> {
-	command::run()
+    command::run()
 }
diff --git a/node/src/rpc/cardano_follower.rs b/node/src/rpc/cardano_follower.rs
index 1ef5ba6..5d66848 100644
--- a/node/src/rpc/cardano_follower.rs
+++ b/node/src/rpc/cardano_follower.rs
@@ -1,15 +1,15 @@
+use aya_runtime::{opaque::Block, RuntimeApi};
+use jsonrpc_core::ErrorCode;
+use jsonrpc_core::{Error as RpcError, ErrorCode as JsonRpcCoreErrorCode, Result as RpcResult};
+use jsonrpc_core_client::RpcChannel;
 use jsonrpc_derive::rpc;
+use jsonrpsee::types::error::ErrorCode as JsonRpcSeeErrorCode;
 use jsonrpsee::RpcModule;
-use jsonrpc_core::{ErrorCode};
 use serde::{Deserialize, Serialize}; // Make sure serde's derive macros are available
-use std::sync::Arc;
 use sp_api::ProvideRuntimeApi;
 use sp_blockchain::HeaderBackend; // Provides the `info()` method
 use sp_runtime::{generic::BlockId, traits::Block as BlockT};
-use jsonrpc_core_client::RpcChannel;
-use jsonrpc_core::{Error as RpcError, Result as RpcResult, ErrorCode as JsonRpcCoreErrorCode};
-use jsonrpsee::types::error::{ErrorCode as JsonRpcSeeErrorCode};
-
+use std::sync::Arc;
 
 /// RPC interface for receiving Cardano follower notifications.
 #[rpc]
@@ -45,6 +45,8 @@ where
         })?;
 
         // Submitting a transaction to the runtime with the parsed event
+        //TODO: Is this really what we ant to do here?
+        //Probably will save to offchain storage
         let api = self.client.runtime_api();
         let at = BlockId::hash(self.client.info().best_hash);
         let result = api.submit_event(&at, parsed_event).map_err(|e| {
@@ -61,7 +63,6 @@ where
     }
 }
 
-
 impl<Client> CardanoFollowerRpcImpl<Client>
 where
     Client: ProvideRuntimeApi<Block> + HeaderBackend<Block> + Send + Sync + 'static,
@@ -69,28 +70,32 @@ where
 {
     pub fn into_rpc(self) -> RpcModule<Self> {
         let mut module = RpcModule::new(self);
-        module.register_async_method("submitCardanoEvent", |params, this| {
-            async move {
-                let event: String = params.parse().map_err(|e| RpcError {
-                    code: ErrorCode::ParseError,
-                    message: "Invalid params".into(),
-                    data: Some(format!("{:?}", e).into()),
-                }).expect("Parameter parsing should not fail");
-                // this.submit_cardano_event(event).map_err(|e| RpcError {
-                //     code: ErrorCode::ServerError(JsonRpcCoreErrorCode::InternalError.into()),
-                //     message: e.message,
-                //     data: e.data,
-                // })
-            }
-        }).expect("Method registration should not fail"); // Changed to expect with a message for clarity
+        module
+            .register_async_method("submitCardanoEvent", |params, this| {
+                async move {
+                    let event: String = params
+                        .parse()
+                        .map_err(|e| RpcError {
+                            code: ErrorCode::ParseError,
+                            message: "Invalid params".into(),
+                            data: Some(format!("{:?}", e).into()),
+                        })
+                        .expect("Parameter parsing should not fail");
+                    //Todo: proper error propagation
+                    // this.submit_cardano_event(event).map_err(|e| RpcError {
+                    //     code: ErrorCode::ServerError(JsonRpcCoreErrorCode::InternalError.into()),
+                    //     message: e.message,
+                    //     data: e.data,
+                    // })
+                }
+            })
+            .expect("Method registration should not fail"); // Changed to expect with a message for clarity
         module
     }
 }
 
-
 #[derive(Deserialize, Debug)]
 pub struct Event {
-
     pub data: String,
 }
 
diff --git a/node/src/rpc/eth.rs b/node/src/rpc/eth.rs
index 29e15a2..e02a105 100644
--- a/node/src/rpc/eth.rs
+++ b/node/src/rpc/eth.rs
@@ -3,9 +3,9 @@ use std::{collections::BTreeMap, sync::Arc};
 use jsonrpsee::RpcModule;
 // Substrate
 use sc_client_api::{
-	backend::{Backend, StorageProvider},
-	client::BlockchainEvents,
-	AuxStore, UsageProvider,
+    backend::{Backend, StorageProvider},
+    client::BlockchainEvents,
+    AuxStore, UsageProvider,
 };
 use sc_network::NetworkService;
 use sc_network_sync::SyncingService;
@@ -27,180 +27,180 @@ use fp_rpc::{ConvertTransaction, ConvertTransactionRuntimeApi, EthereumRuntimeRP
 
 /// Extra dependencies for Ethereum compatibility.
 pub struct EthDeps<B: BlockT, C, P, A: ChainApi, CT, CIDP> {
-	/// The client instance to use.
-	pub client: Arc<C>,
-	/// Transaction pool instance.
-	pub pool: Arc<P>,
-	/// Graph pool instance.
-	pub graph: Arc<Pool<A>>,
-	/// Ethereum transaction converter.
-	pub converter: Option<CT>,
-	/// The Node authority flag
-	pub is_authority: bool,
-	/// Whether to enable dev signer
-	pub enable_dev_signer: bool,
-	/// Network service
-	pub network: Arc<NetworkService<B, B::Hash>>,
-	/// Chain syncing service
-	pub sync: Arc<SyncingService<B>>,
-	/// Frontier Backend.
-	pub frontier_backend: Arc<dyn fc_api::Backend<B>>,
-	/// Ethereum data access overrides.
-	pub overrides: Arc<OverrideHandle<B>>,
-	/// Cache for Ethereum block data.
-	pub block_data_cache: Arc<EthBlockDataCacheTask<B>>,
-	/// EthFilterApi pool.
-	pub filter_pool: Option<FilterPool>,
-	/// Maximum number of logs in a query.
-	pub max_past_logs: u32,
-	/// Fee history cache.
-	pub fee_history_cache: FeeHistoryCache,
-	/// Maximum fee history cache size.
-	pub fee_history_cache_limit: FeeHistoryCacheLimit,
-	/// Maximum allowed gas limit will be ` block.gas_limit * execute_gas_limit_multiplier` when
-	/// using eth_call/eth_estimateGas.
-	pub execute_gas_limit_multiplier: u64,
-	/// Mandated parent hashes for a given block hash.
-	pub forced_parent_hashes: Option<BTreeMap<H256, H256>>,
-	/// Something that can create the inherent data providers for pending state
-	pub pending_create_inherent_data_providers: CIDP,
+    /// The client instance to use.
+    pub client: Arc<C>,
+    /// Transaction pool instance.
+    pub pool: Arc<P>,
+    /// Graph pool instance.
+    pub graph: Arc<Pool<A>>,
+    /// Ethereum transaction converter.
+    pub converter: Option<CT>,
+    /// The Node authority flag
+    pub is_authority: bool,
+    /// Whether to enable dev signer
+    pub enable_dev_signer: bool,
+    /// Network service
+    pub network: Arc<NetworkService<B, B::Hash>>,
+    /// Chain syncing service
+    pub sync: Arc<SyncingService<B>>,
+    /// Frontier Backend.
+    pub frontier_backend: Arc<dyn fc_api::Backend<B>>,
+    /// Ethereum data access overrides.
+    pub overrides: Arc<OverrideHandle<B>>,
+    /// Cache for Ethereum block data.
+    pub block_data_cache: Arc<EthBlockDataCacheTask<B>>,
+    /// EthFilterApi pool.
+    pub filter_pool: Option<FilterPool>,
+    /// Maximum number of logs in a query.
+    pub max_past_logs: u32,
+    /// Fee history cache.
+    pub fee_history_cache: FeeHistoryCache,
+    /// Maximum fee history cache size.
+    pub fee_history_cache_limit: FeeHistoryCacheLimit,
+    /// Maximum allowed gas limit will be ` block.gas_limit * execute_gas_limit_multiplier` when
+    /// using eth_call/eth_estimateGas.
+    pub execute_gas_limit_multiplier: u64,
+    /// Mandated parent hashes for a given block hash.
+    pub forced_parent_hashes: Option<BTreeMap<H256, H256>>,
+    /// Something that can create the inherent data providers for pending state
+    pub pending_create_inherent_data_providers: CIDP,
 }
 
 /// Instantiate Ethereum-compatible RPC extensions.
 pub fn create_eth<B, C, BE, P, A, CT, CIDP, EC>(
-	mut io: RpcModule<()>,
-	deps: EthDeps<B, C, P, A, CT, CIDP>,
-	subscription_task_executor: SubscriptionTaskExecutor,
-	pubsub_notification_sinks: Arc<
-		fc_mapping_sync::EthereumBlockNotificationSinks<
-			fc_mapping_sync::EthereumBlockNotification<B>,
-		>,
-	>,
+    mut io: RpcModule<()>,
+    deps: EthDeps<B, C, P, A, CT, CIDP>,
+    subscription_task_executor: SubscriptionTaskExecutor,
+    pubsub_notification_sinks: Arc<
+        fc_mapping_sync::EthereumBlockNotificationSinks<
+            fc_mapping_sync::EthereumBlockNotification<B>,
+        >,
+    >,
 ) -> Result<RpcModule<()>, Box<dyn std::error::Error + Send + Sync>>
 where
-	B: BlockT<Hash = H256>,
-	C: CallApiAt<B> + ProvideRuntimeApi<B>,
-	C::Api: AuraApi<B, AuraId>
-		+ BlockBuilderApi<B>
-		+ ConvertTransactionRuntimeApi<B>
-		+ EthereumRuntimeRPCApi<B>,
-	C: HeaderBackend<B> + HeaderMetadata<B, Error = BlockChainError>,
-	C: BlockchainEvents<B> + AuxStore + UsageProvider<B> + StorageProvider<B, BE> + 'static,
-	BE: Backend<B> + 'static,
-	P: TransactionPool<Block = B> + 'static,
-	A: ChainApi<Block = B> + 'static,
-	CT: ConvertTransaction<<B as BlockT>::Extrinsic> + Send + Sync + 'static,
-	CIDP: CreateInherentDataProviders<B, ()> + Send + 'static,
-	EC: EthConfig<B, C>,
+    B: BlockT<Hash = H256>,
+    C: CallApiAt<B> + ProvideRuntimeApi<B>,
+    C::Api: AuraApi<B, AuraId>
+        + BlockBuilderApi<B>
+        + ConvertTransactionRuntimeApi<B>
+        + EthereumRuntimeRPCApi<B>,
+    C: HeaderBackend<B> + HeaderMetadata<B, Error = BlockChainError>,
+    C: BlockchainEvents<B> + AuxStore + UsageProvider<B> + StorageProvider<B, BE> + 'static,
+    BE: Backend<B> + 'static,
+    P: TransactionPool<Block = B> + 'static,
+    A: ChainApi<Block = B> + 'static,
+    CT: ConvertTransaction<<B as BlockT>::Extrinsic> + Send + Sync + 'static,
+    CIDP: CreateInherentDataProviders<B, ()> + Send + 'static,
+    EC: EthConfig<B, C>,
 {
-	use fc_rpc::{
-		pending::AuraConsensusDataProvider, Debug, DebugApiServer, Eth, EthApiServer, EthDevSigner,
-		EthFilter, EthFilterApiServer, EthPubSub, EthPubSubApiServer, EthSigner, Net, NetApiServer,
-		Web3, Web3ApiServer,
-	};
-	#[cfg(feature = "txpool")]
-	use fc_rpc::{TxPool, TxPoolApiServer};
+    use fc_rpc::{
+        pending::AuraConsensusDataProvider, Debug, DebugApiServer, Eth, EthApiServer, EthDevSigner,
+        EthFilter, EthFilterApiServer, EthPubSub, EthPubSubApiServer, EthSigner, Net, NetApiServer,
+        Web3, Web3ApiServer,
+    };
+    #[cfg(feature = "txpool")]
+    use fc_rpc::{TxPool, TxPoolApiServer};
 
-	let EthDeps {
-		client,
-		pool,
-		graph,
-		converter,
-		is_authority,
-		enable_dev_signer,
-		network,
-		sync,
-		frontier_backend,
-		overrides,
-		block_data_cache,
-		filter_pool,
-		max_past_logs,
-		fee_history_cache,
-		fee_history_cache_limit,
-		execute_gas_limit_multiplier,
-		forced_parent_hashes,
-		pending_create_inherent_data_providers,
-	} = deps;
+    let EthDeps {
+        client,
+        pool,
+        graph,
+        converter,
+        is_authority,
+        enable_dev_signer,
+        network,
+        sync,
+        frontier_backend,
+        overrides,
+        block_data_cache,
+        filter_pool,
+        max_past_logs,
+        fee_history_cache,
+        fee_history_cache_limit,
+        execute_gas_limit_multiplier,
+        forced_parent_hashes,
+        pending_create_inherent_data_providers,
+    } = deps;
 
-	let mut signers = Vec::new();
-	if enable_dev_signer {
-		signers.push(Box::new(EthDevSigner::new()) as Box<dyn EthSigner>);
-	}
+    let mut signers = Vec::new();
+    if enable_dev_signer {
+        signers.push(Box::new(EthDevSigner::new()) as Box<dyn EthSigner>);
+    }
 
-	io.merge(
-		Eth::<B, C, P, CT, BE, A, CIDP, EC>::new(
-			client.clone(),
-			pool.clone(),
-			graph.clone(),
-			converter,
-			sync.clone(),
-			signers,
-			overrides.clone(),
-			frontier_backend.clone(),
-			is_authority,
-			block_data_cache.clone(),
-			fee_history_cache,
-			fee_history_cache_limit,
-			execute_gas_limit_multiplier,
-			forced_parent_hashes,
-			pending_create_inherent_data_providers,
-			Some(Box::new(AuraConsensusDataProvider::new(client.clone()))),
-		)
-		.replace_config::<EC>()
-		.into_rpc(),
-	)?;
+    io.merge(
+        Eth::<B, C, P, CT, BE, A, CIDP, EC>::new(
+            client.clone(),
+            pool.clone(),
+            graph.clone(),
+            converter,
+            sync.clone(),
+            signers,
+            overrides.clone(),
+            frontier_backend.clone(),
+            is_authority,
+            block_data_cache.clone(),
+            fee_history_cache,
+            fee_history_cache_limit,
+            execute_gas_limit_multiplier,
+            forced_parent_hashes,
+            pending_create_inherent_data_providers,
+            Some(Box::new(AuraConsensusDataProvider::new(client.clone()))),
+        )
+        .replace_config::<EC>()
+        .into_rpc(),
+    )?;
 
-	if let Some(filter_pool) = filter_pool {
-		io.merge(
-			EthFilter::new(
-				client.clone(),
-				frontier_backend.clone(),
-				graph.clone(),
-				filter_pool,
-				500_usize, // max stored filters
-				max_past_logs,
-				block_data_cache.clone(),
-			)
-			.into_rpc(),
-		)?;
-	}
+    if let Some(filter_pool) = filter_pool {
+        io.merge(
+            EthFilter::new(
+                client.clone(),
+                frontier_backend.clone(),
+                graph.clone(),
+                filter_pool,
+                500_usize, // max stored filters
+                max_past_logs,
+                block_data_cache.clone(),
+            )
+            .into_rpc(),
+        )?;
+    }
 
-	io.merge(
-		EthPubSub::new(
-			pool,
-			client.clone(),
-			sync,
-			subscription_task_executor,
-			overrides.clone(),
-			pubsub_notification_sinks,
-		)
-		.into_rpc(),
-	)?;
+    io.merge(
+        EthPubSub::new(
+            pool,
+            client.clone(),
+            sync,
+            subscription_task_executor,
+            overrides.clone(),
+            pubsub_notification_sinks,
+        )
+        .into_rpc(),
+    )?;
 
-	io.merge(
-		Net::new(
-			client.clone(),
-			network,
-			// Whether to format the `peer_count` response as Hex (default) or not.
-			true,
-		)
-		.into_rpc(),
-	)?;
+    io.merge(
+        Net::new(
+            client.clone(),
+            network,
+            // Whether to format the `peer_count` response as Hex (default) or not.
+            true,
+        )
+        .into_rpc(),
+    )?;
 
-	io.merge(Web3::new(client.clone()).into_rpc())?;
+    io.merge(Web3::new(client.clone()).into_rpc())?;
 
-	io.merge(
-		Debug::new(
-			client.clone(),
-			frontier_backend,
-			overrides,
-			block_data_cache,
-		)
-		.into_rpc(),
-	)?;
+    io.merge(
+        Debug::new(
+            client.clone(),
+            frontier_backend,
+            overrides,
+            block_data_cache,
+        )
+        .into_rpc(),
+    )?;
 
-	#[cfg(feature = "txpool")]
-	io.merge(TxPool::new(client, graph).into_rpc())?;
+    #[cfg(feature = "txpool")]
+    io.merge(TxPool::new(client, graph).into_rpc())?;
 
-	Ok(io)
+    Ok(io)
 }
diff --git a/node/src/rpc/mod.rs b/node/src/rpc/mod.rs
index 52d39bb..9cf1d90 100644
--- a/node/src/rpc/mod.rs
+++ b/node/src/rpc/mod.rs
@@ -6,9 +6,9 @@ use futures::channel::mpsc;
 use jsonrpsee::RpcModule;
 // Substrate
 use sc_client_api::{
-	backend::{Backend, StorageProvider},
-	client::BlockchainEvents,
-	AuxStore, UsageProvider,
+    backend::{Backend, StorageProvider},
+    client::BlockchainEvents,
+    AuxStore, UsageProvider,
 };
 use sc_consensus_manual_seal::rpc::EngineCommand;
 use sc_rpc::SubscriptionTaskExecutor;
@@ -30,95 +30,93 @@ pub use self::eth::{create_eth, overrides_handle, EthDeps};
 
 /// Full client dependencies.
 pub struct FullDeps<C, P, A: ChainApi, CT, CIDP> {
-	/// The client instance to use.
-	pub client: Arc<C>,
-	/// Transaction pool instance.
-	pub pool: Arc<P>,
-	/// Whether to deny unsafe calls
-	pub deny_unsafe: DenyUnsafe,
-	/// Manual seal command sink
-	pub command_sink: Option<mpsc::Sender<EngineCommand<Hash>>>,
-	/// Ethereum-compatibility specific dependencies.
-	pub eth: EthDeps<Block, C, P, A, CT, CIDP>,
+    /// The client instance to use.
+    pub client: Arc<C>,
+    /// Transaction pool instance.
+    pub pool: Arc<P>,
+    /// Whether to deny unsafe calls
+    pub deny_unsafe: DenyUnsafe,
+    /// Manual seal command sink
+    pub command_sink: Option<mpsc::Sender<EngineCommand<Hash>>>,
+    /// Ethereum-compatibility specific dependencies.
+    pub eth: EthDeps<Block, C, P, A, CT, CIDP>,
 }
 
 pub struct DefaultEthConfig<C, BE>(std::marker::PhantomData<(C, BE)>);
 
 impl<C, BE> fc_rpc::EthConfig<Block, C> for DefaultEthConfig<C, BE>
 where
-	C: StorageProvider<Block, BE> + Sync + Send + 'static,
-	BE: Backend<Block> + 'static,
+    C: StorageProvider<Block, BE> + Sync + Send + 'static,
+    BE: Backend<Block> + 'static,
 {
-	type EstimateGasAdapter = ();
-	type RuntimeStorageOverride =
-		fc_rpc::frontier_backend_client::SystemAccountId20StorageOverride<Block, C, BE>;
+    type EstimateGasAdapter = ();
+    type RuntimeStorageOverride =
+        fc_rpc::frontier_backend_client::SystemAccountId20StorageOverride<Block, C, BE>;
 }
 
 /// Instantiate all Full RPC extensions.
 pub fn create_full<C, P, BE, A, CT, CIDP>(
-	deps: FullDeps<C, P, A, CT, CIDP>,
-	subscription_task_executor: SubscriptionTaskExecutor,
-	pubsub_notification_sinks: Arc<
-		fc_mapping_sync::EthereumBlockNotificationSinks<
-			fc_mapping_sync::EthereumBlockNotification<Block>,
-		>,
-	>,
+    deps: FullDeps<C, P, A, CT, CIDP>,
+    subscription_task_executor: SubscriptionTaskExecutor,
+    pubsub_notification_sinks: Arc<
+        fc_mapping_sync::EthereumBlockNotificationSinks<
+            fc_mapping_sync::EthereumBlockNotification<Block>,
+        >,
+    >,
 ) -> Result<RpcModule<()>, Box<dyn std::error::Error + Send + Sync>>
 where
-	C: ProvideRuntimeApi<Block> + BlockchainEvents<Block> + 'static,
-	C: CallApiAt<Block> + ProvideRuntimeApi<Block>,
-	C::Api: sp_block_builder::BlockBuilder<Block>,
-	C::Api: sp_consensus_aura::AuraApi<Block, AuraId>,
-	C::Api: substrate_frame_rpc_system::AccountNonceApi<Block, AccountId, Nonce>,
-	C::Api: pallet_transaction_payment_rpc::TransactionPaymentRuntimeApi<Block, Balance>,
-	C::Api: fp_rpc::ConvertTransactionRuntimeApi<Block>,
-	C::Api: fp_rpc::EthereumRuntimeRPCApi<Block>,
-	C: HeaderBackend<Block> + HeaderMetadata<Block, Error = BlockChainError> + 'static,
-	C: BlockchainEvents<Block> + AuxStore + UsageProvider<Block> + StorageProvider<Block, BE>,
-	BE: Backend<Block> + 'static,
-	P: TransactionPool<Block = Block> + 'static,
-	A: ChainApi<Block = Block> + 'static,
-	CIDP: CreateInherentDataProviders<Block, ()> + Send + 'static,
-	CT: fp_rpc::ConvertTransaction<<Block as BlockT>::Extrinsic> + Send + Sync + 'static,
+    C: ProvideRuntimeApi<Block> + BlockchainEvents<Block> + 'static,
+    C: CallApiAt<Block> + ProvideRuntimeApi<Block>,
+    C::Api: sp_block_builder::BlockBuilder<Block>,
+    C::Api: sp_consensus_aura::AuraApi<Block, AuraId>,
+    C::Api: substrate_frame_rpc_system::AccountNonceApi<Block, AccountId, Nonce>,
+    C::Api: pallet_transaction_payment_rpc::TransactionPaymentRuntimeApi<Block, Balance>,
+    C::Api: fp_rpc::ConvertTransactionRuntimeApi<Block>,
+    C::Api: fp_rpc::EthereumRuntimeRPCApi<Block>,
+    C: HeaderBackend<Block> + HeaderMetadata<Block, Error = BlockChainError> + 'static,
+    C: BlockchainEvents<Block> + AuxStore + UsageProvider<Block> + StorageProvider<Block, BE>,
+    BE: Backend<Block> + 'static,
+    P: TransactionPool<Block = Block> + 'static,
+    A: ChainApi<Block = Block> + 'static,
+    CIDP: CreateInherentDataProviders<Block, ()> + Send + 'static,
+    CT: fp_rpc::ConvertTransaction<<Block as BlockT>::Extrinsic> + Send + Sync + 'static,
 {
-	use pallet_transaction_payment_rpc::{TransactionPayment, TransactionPaymentApiServer};
-	use sc_consensus_manual_seal::rpc::{ManualSeal, ManualSealApiServer};
-	use substrate_frame_rpc_system::{System, SystemApiServer};
+    use pallet_transaction_payment_rpc::{TransactionPayment, TransactionPaymentApiServer};
+    use sc_consensus_manual_seal::rpc::{ManualSeal, ManualSealApiServer};
+    use substrate_frame_rpc_system::{System, SystemApiServer};
 
-	let mut io = RpcModule::new(());
-	let FullDeps {
-		client,
-		pool,
-		deny_unsafe,
-		command_sink,
-		eth,
-	} = deps;
+    let mut io = RpcModule::new(());
+    let FullDeps {
+        client,
+        pool,
+        deny_unsafe,
+        command_sink,
+        eth,
+    } = deps;
 
-	io.merge(System::new(client.clone(), pool, deny_unsafe).into_rpc())?;
-	io.merge(TransactionPayment::new(client.clone()).into_rpc())?;
+    io.merge(System::new(client.clone(), pool, deny_unsafe).into_rpc())?;
+    io.merge(TransactionPayment::new(client.clone()).into_rpc())?;
 
-	if let Some(command_sink) = command_sink {
-		io.merge(
-			// We provide the rpc handler with the sending end of the channel to allow the rpc
-			// send EngineCommands to the background block authorship task.
-			ManualSeal::new(command_sink).into_rpc(),
-		)?;
-	}
+    if let Some(command_sink) = command_sink {
+        io.merge(
+            // We provide the rpc handler with the sending end of the channel to allow the rpc
+            // send EngineCommands to the background block authorship task.
+            ManualSeal::new(command_sink).into_rpc(),
+        )?;
+    }
 
-	// Ethereum compatibility RPCs
-	let io = create_eth::<_, _, _, _, _, _, _, DefaultEthConfig<C, BE>>(
-		io,
-		eth,
-		subscription_task_executor,
-		pubsub_notification_sinks,
-	)?;
-	let cardano_rpc = CardanoFollowerRpcImpl {
-		client: client.clone(),
-	};
-	
-	// io.merge(cardano_rpc.into_rpc())?;
-	
-	
+    // Ethereum compatibility RPCs
+    let io = create_eth::<_, _, _, _, _, _, _, DefaultEthConfig<C, BE>>(
+        io,
+        eth,
+        subscription_task_executor,
+        pubsub_notification_sinks,
+    )?;
+    let cardano_rpc = CardanoFollowerRpcImpl {
+        client: client.clone(),
+    };
 
-	Ok(io)
+    // io.merge(cardano_rpc.into_rpc())?;
+
+    Ok(io)
 }
diff --git a/pallets/chain-listener/Cargo.toml b/pallets/chain-listener/Cargo.toml
index f42e34e..706e34f 100644
--- a/pallets/chain-listener/Cargo.toml
+++ b/pallets/chain-listener/Cargo.toml
@@ -21,7 +21,8 @@ scale-info = { workspace = true }
 log = { workspace = true }
 scale-codec = { workspace = true }
 sp-consensus-aura = { workspace = true }
-
+sp-std = {workspace = true}
+serde = { workspace = true }	
 [features]
 default = ["std"]
 std = [
@@ -33,6 +34,9 @@ std = [
 	"sp-core/std",
 	"sp-io/std",
 	"sp-runtime/std",
+	"sp-std/std",
+	"serde/std",
+
 ]
 runtime-benchmarks = [
 	"frame-benchmarking/runtime-benchmarks",
diff --git a/pallets/chain-listener/src/benchmarking.rs b/pallets/chain-listener/src/benchmarking.rs
index c7d7913..9c36a3d 100644
--- a/pallets/chain-listener/src/benchmarking.rs
+++ b/pallets/chain-listener/src/benchmarking.rs
@@ -9,27 +9,27 @@ use frame_system::RawOrigin;
 
 #[benchmarks]
 mod benchmarks {
-	use super::*;
+    use super::*;
 
-	#[benchmark]
-	fn do_something() {
-		let value = 100u32.into();
-		let caller: T::AccountId = whitelisted_caller();
-		#[extrinsic_call]
-		do_something(RawOrigin::Signed(caller), value);
+    #[benchmark]
+    fn do_something() {
+        let value = 100u32.into();
+        let caller: T::AccountId = whitelisted_caller();
+        #[extrinsic_call]
+        do_something(RawOrigin::Signed(caller), value);
 
-		assert_eq!(Something::<T>::get(), Some(value));
-	}
+        assert_eq!(Something::<T>::get(), Some(value));
+    }
 
-	#[benchmark]
-	fn cause_error() {
-		Something::<T>::put(100u32);
-		let caller: T::AccountId = whitelisted_caller();
-		#[extrinsic_call]
-		cause_error(RawOrigin::Signed(caller));
+    #[benchmark]
+    fn cause_error() {
+        Something::<T>::put(100u32);
+        let caller: T::AccountId = whitelisted_caller();
+        #[extrinsic_call]
+        cause_error(RawOrigin::Signed(caller));
 
-		assert_eq!(Something::<T>::get(), Some(101u32));
-	}
+        assert_eq!(Something::<T>::get(), Some(101u32));
+    }
 
-	impl_benchmark_test_suite!(Listener, crate::mock::new_test_ext(), crate::mock::Test);
+    impl_benchmark_test_suite!(Listener, crate::mock::new_test_ext(), crate::mock::Test);
 }
diff --git a/pallets/chain-listener/src/lib.rs b/pallets/chain-listener/src/lib.rs
index 6ef6ec6..fcd94fe 100644
--- a/pallets/chain-listener/src/lib.rs
+++ b/pallets/chain-listener/src/lib.rs
@@ -1,10 +1,14 @@
 #![cfg_attr(not(feature = "std"), no_std)]
+extern crate sp_std;
+#[cfg_attr(feature = "std", macro_use)]
+extern crate serde;
 
+#[cfg(feature = "std")]
+use serde::{Serialize, Deserialize};
 pub use pallet::*;
 #[cfg(test)]
 mod tests;
 
-
 #[cfg(feature = "runtime-benchmarks")]
 mod benchmarking;
 pub mod weights;
@@ -12,49 +16,145 @@ pub use weights::*;
 
 #[frame_support::pallet]
 pub mod pallet {
-    use frame_support::{pallet_prelude::*, weights::Weight};
-    use frame_system::{pallet_prelude::*, offchain::*};
-    use sp_runtime::offchain::*;
+    use frame_support::{dispatch::DispatchResult, pallet_prelude::*, weights::Weight};
+    use frame_system::{offchain::*, pallet_prelude::*};
     use sp_consensus_aura::ed25519::AuthorityId;
-   
     use sp_core::Public;
+    use sp_runtime::offchain::*;
+    use sp_runtime::offchain::{http, Duration};
+    use sp_std::prelude::*;
+    
+    
 
-	#[pallet::config]
-	pub trait Config: frame_system::Config + CreateSignedTransaction<Call<Self>> {
-		type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;
-		type WeightInfo: WeightInfo;
-		type AuthorityId: Public;
-        
+
+    #[pallet::config]
+    pub trait Config: frame_system::Config + CreateSignedTransaction<Call<Self>> {
+        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;
+        type WeightInfo: WeightInfo;
+        type AuthorityId: Public;
+        // Authority identifier for signing transactions
+        // type AuthorityId: AppCrypto<Self::Public, Self::Signature>;
     }
 
     #[pallet::pallet]
-	
     #[pallet::without_storage_info]
     pub struct Pallet<T>(_);
 
     #[pallet::hooks]
     impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {
-       
         fn offchain_worker(block_number: BlockNumberFor<T>) {
-            // off-chain worker logic
-            log::info!("Hello from offchain worker: {:?}", block_number);
+            // if let Err(e) = Self::fetch_and_send_data() {
+            //     log::error!("Error fetching and sending data: {:?}", e);
+            // }
+        }
+    }
+
+    
+    impl<T: Config> Pallet<T> {
+        // fn construct_url(path: &str) -> String {
+        //     const DEFAULT_HOST: &str = "http://scrolls-1";
+        //     const DEFAULT_PORT: &str = "4123";
+
+        //     format!("{}:{}{}", DEFAULT_HOST, DEFAULT_PORT, path)
+        // }
+
+        // fn fetch_and_process_data() -> Result<(), &'static str> {
+        //     // Example: Fetch data from multiple endpoints
+        //     let assets_url = Self::construct_url("/api/info/address/stake/assets/");
+        //     Self::fetch_data(&assets_url)?;
+
+        //     let pools_url = Self::construct_url("/api/info/pools/1"); // example with page number
+        //     Self::fetch_data(&pools_url)?;
+
+        //     Ok(())
+        // }
+
+        // fn fetch_data(url: &str) -> Result<(), &'static str> {
+        //     let request = http::Request::get(url);
+
+        //     // Add headers and set timeout
+        //     let pending = request
+        //         .add_header("User-Agent", "SubstrateOffchainWorker")
+        //         .deadline(Duration::from_millis(8_000))
+        //         .send()
+        //         .map_err(|_| "Failed to send request")?;
+
+        //     // Handling the response
+        //     let response = pending
+        //         .try_wait(Duration::from_millis(5_000))
+        //         .map_err(|_| "Timeout while waiting for response")?
+        //         .map_err(|_| "Failed to receive response")?;
+
+        //     if response.code != 200 {
+        //         log::error!("Unexpected status code: {}", response.code);
+        //         return Err("Non-200 status code returned from API");
+        //     }
+
+        //     // Log the successful fetch
+        //     log::info!("Successfully fetched data from: {}", url);
+        //     Self::process_response(response.body().collect::<Vec<u8>>())?;
+
+        //     Ok(())
+        // }
+
+        // fn process_response(data: Vec<u8>) -> Result<(), &'static str> {
+        //     // Here you would parse the JSON and do something with it
+        //     log::info!("Data received: {:?}", String::from_utf8_lossy(&data));
+        //     Ok(())
+        // }
+    }
+    use sp_runtime::Deserialize;
+    use scale_info::prelude::string::String;
+    #[derive(Deserialize, Debug)]
+    struct Asset {
+        // Define the expected fields
+        asset_id: String,
+        quantity: u64,
+    }
+
+    impl<T: Config> Pallet<T> {
+        fn process_response(data: Vec<u8>) -> Result<(), &'static str> {
+            // if let Ok(assets) = serde_json::from_slice::<Vec<Asset>>(&data) {
+            //     // Process each asset
+            //     for asset in assets {
+            //         log::info!("Asset ID: {}, Quantity: {}", asset.asset_id, asset.quantity);
+            //     }
+            // } else {
+            //     log::error!("Failed to parse JSON data");
+            //     return Err("Failed to parse JSON");
+            // }
+
+            Ok(())
         }
     }
 
     #[pallet::call]
     impl<T: Config> Pallet<T> {
-        // Add your extrinsics here
+        // #[pallet::weight(10_000)]
+        // pub fn trigger_fetch(origin: OriginFor<T>) -> DispatchResult {
+        //     let _who = ensure_signed(origin)?;
+
+        //     match Self::fetch_and_process_data() {
+        //         Ok(_) => {
+        //             Self::deposit_event(Event::DataFetchedSuccessfully);
+        //             Ok(())
+        //         },
+        //         Err(_e) => {
+        //             Err(Error::<T>::HttpFetchingError.into())
+        //         }
+        //     }
+        // }
     }
 
     #[pallet::error]
     pub enum Error<T> {
-        // Add your error variants here
+       
     }
 
     #[pallet::event]
     #[pallet::generate_deposit(pub(super) fn deposit_event)]
     pub enum Event<T: Config> {
-        // Add your event variants here
+        
     }
 
     #[pallet::type_value]
@@ -62,15 +162,94 @@ pub mod pallet {
         ()
     }
 
-	pub trait WeightInfo {
-		fn some_extrinsic() -> Weight {
-			Weight::zero()
-		}
-	}
-	
-	impl WeightInfo for () {
-		fn some_extrinsic() -> Weight {
-			Weight::zero()
-		}
-	}
-}
\ No newline at end of file
+    pub trait WeightInfo {
+        fn some_extrinsic() -> Weight {
+            Weight::zero()
+        }
+    }
+
+    impl WeightInfo for () {
+        fn some_extrinsic() -> Weight {
+            Weight::zero()
+        }
+    }
+}
+// fn fetch_address_stake_assets() -> Result<(), &'static str> {
+//     let url = construct_url("/api/info/address/stake/assets/");
+//     let data = fetch_data(&url)?;
+//     process_address_stake_assets(data)
+// }
+
+
+// fn fetch_addresses_assets() -> Result<(), &'static str> {
+//     let url = construct_url("/api/info/addresses/assets/");
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+// fn fetch_pools(page: u32) -> Result<(), &'static str> {
+//     let url = construct_url(&format!("/api/info/pools/{}", page));
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+
+// fn fetch_token_nft_status() -> Result<(), &'static str> {
+//     let url = construct_url("/api/info/tokens/isNft/");
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+
+// fn fetch_epoch_stake_amount(stake_addr: &str, epoch: u32) -> Result<(), &'static str> {
+//     let url = construct_url(&format!("/api/info/epoch/stake/amount/{}/{}", stake_addr, epoch));
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+// fn fetch_reward_amount(stake_addr: &str) -> Result<(), &'static str> {
+//     let url = construct_url(&format!("/api/info/reward/amount/{}", stake_addr));
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+// fn fetch_epoch_changes(from_epoch: u32, to_epoch: u32) -> Result<(), &'static str> {
+//     let url = construct_url(&format!("/api/aya/epoch/change/from/{}/{}", from_epoch, to_epoch));
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+// fn fetch_latest_epoch_change() -> Result<(), &'static str> {
+//     let url = construct_url("/api/aya/epoch/change/latest");
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+
+
+// fn fetch_current_epoch() -> Result<(), &'static str> {
+//     let url = construct_url("/api/aya/epoch/current/");
+//     let data = fetch_data(&url)?;
+//     // Process data as needed
+//     Ok(())
+// }
+
+
+
+// fn construct_url(endpoint: &str) -> String {
+//     format!("{}:{}{}", DEFAULT_HOST, DEFAULT_PORT, endpoint)
+// }
\ No newline at end of file
diff --git a/pallets/chain-listener/src/tests.rs b/pallets/chain-listener/src/tests.rs
index 83e4bea..18d9967 100644
--- a/pallets/chain-listener/src/tests.rs
+++ b/pallets/chain-listener/src/tests.rs
@@ -3,25 +3,31 @@ use frame_support::{assert_noop, assert_ok};
 
 #[test]
 fn it_works_for_default_value() {
-	new_test_ext().execute_with(|| {
-		// Go past genesis block so events get deposited
-		System::set_block_number(1);
-		// Dispatch a signed extrinsic.
-		assert_ok!(TemplateModule::do_something(RuntimeOrigin::signed(1), 42));
-		// Read pallet storage and assert an expected result.
-		assert_eq!(Something::<Test>::get(), Some(42));
-		// Assert that the correct event was deposited
-		System::assert_last_event(Event::SomethingStored { something: 42, who: 1 }.into());
-	});
+    new_test_ext().execute_with(|| {
+        // Go past genesis block so events get deposited
+        System::set_block_number(1);
+        // Dispatch a signed extrinsic.
+        assert_ok!(TemplateModule::do_something(RuntimeOrigin::signed(1), 42));
+        // Read pallet storage and assert an expected result.
+        assert_eq!(Something::<Test>::get(), Some(42));
+        // Assert that the correct event was deposited
+        System::assert_last_event(
+            Event::SomethingStored {
+                something: 42,
+                who: 1,
+            }
+            .into(),
+        );
+    });
 }
 
 #[test]
 fn correct_error_for_none_value() {
-	new_test_ext().execute_with(|| {
-		// Ensure the expected error is thrown when no value is present.
-		assert_noop!(
-			TemplateModule::cause_error(RuntimeOrigin::signed(1)),
-			Error::<Test>::NoneValue
-		);
-	});
+    new_test_ext().execute_with(|| {
+        // Ensure the expected error is thrown when no value is present.
+        assert_noop!(
+            TemplateModule::cause_error(RuntimeOrigin::signed(1)),
+            Error::<Test>::NoneValue
+        );
+    });
 }
diff --git a/pallets/substrate-validator-set/src/mock.rs b/pallets/substrate-validator-set/src/mock.rs
index 8fc2282..3c1893e 100644
--- a/pallets/substrate-validator-set/src/mock.rs
+++ b/pallets/substrate-validator-set/src/mock.rs
@@ -81,8 +81,8 @@ pub struct TestShouldEndSession;
 impl ShouldEndSession<u64> for TestShouldEndSession {
 	fn should_end_session(now: u64) -> bool {
 		let l = SessionLength::get();
-		now % l == 0
-			|| ForceSessionEnd::mutate(|l| {
+		now % l == 0 ||
+			ForceSessionEnd::mutate(|l| {
 				let r = *l;
 				*l = false;
 				r
diff --git a/runtime/build.rs b/runtime/build.rs
index 9029164..6db3d90 100644
--- a/runtime/build.rs
+++ b/runtime/build.rs
@@ -1,8 +1,8 @@
 fn main() {
-	#[cfg(feature = "std")]
-	substrate_wasm_builder::WasmBuilder::new()
-		.with_current_project()
-		.export_heap_base()
-		.import_memory()
-		.build()
+    #[cfg(feature = "std")]
+    substrate_wasm_builder::WasmBuilder::new()
+        .with_current_project()
+        .export_heap_base()
+        .import_memory()
+        .build()
 }
diff --git a/runtime/src/assets_api.rs b/runtime/src/assets_api.rs
index 31927fb..b3e2dda 100644
--- a/runtime/src/assets_api.rs
+++ b/runtime/src/assets_api.rs
@@ -22,13 +22,13 @@ use scale_codec::Codec;
 use sp_std::vec::Vec;
 
 sp_api::decl_runtime_apis! {
-	pub trait AssetsApi<AccountId, AssetBalance, AssetId>
-	where
-		AccountId: Codec,
-		AssetBalance: Codec,
-		AssetId: Codec,
-	{
-		/// Returns the list of `AssetId`s and corresponding balance that an `AccountId` has.
-		fn account_balances(account: AccountId) -> Vec<(AssetId, AssetBalance)>;
-	}
+    pub trait AssetsApi<AccountId, AssetBalance, AssetId>
+    where
+        AccountId: Codec,
+        AssetBalance: Codec,
+        AssetId: Codec,
+    {
+        /// Returns the list of `AssetId`s and corresponding balance that an `AccountId` has.
+        fn account_balances(account: AccountId) -> Vec<(AssetId, AssetBalance)>;
+    }
 }
diff --git a/runtime/src/lib.rs b/runtime/src/lib.rs
index 7449bf1..a7bc2c9 100644
--- a/runtime/src/lib.rs
+++ b/runtime/src/lib.rs
@@ -71,7 +71,6 @@ use pallet_evm::{
 };
 use pallet_im_online::sr25519::AuthorityId as ImOnlineId;
 
-
 // A few exports that help ease life for downstream crates.
 pub use frame_system::Call as SystemCall;
 pub use pallet_balances::Call as BalancesCall;
@@ -80,7 +79,6 @@ use pallet_transaction_payment::Multiplier;
 
 pub use chain_listener;
 
-
 mod precompiles;
 
 /// Runtime API definition for assets.
@@ -336,11 +334,9 @@ use sp_consensus_aura::ed25519::AuthorityId;
 impl chain_listener::Config for Runtime {
     type RuntimeEvent = RuntimeEvent;
     type WeightInfo = ();
-    type AuthorityId = AuthorityId;   
-
+    type AuthorityId = AuthorityId;
 }
 
-
 parameter_types! {
     pub const Period: u32 = 2 * MINUTES;
     pub const Offset: u32 = 0;
@@ -773,8 +769,6 @@ impl pallet_manual_seal::Config for Runtime {}
 
 impl pallet_insecure_randomness_collective_flip::Config for Runtime {}
 
-
-
 // Create the runtime by composing the FRAME pallets that were previously configured.
 frame_support::construct_runtime!(
     pub enum Runtime {
diff --git a/runtime/src/precompiles.rs b/runtime/src/precompiles.rs
index c563f8e..dda5335 100644
--- a/runtime/src/precompiles.rs
+++ b/runtime/src/precompiles.rs
@@ -1,5 +1,5 @@
 use pallet_evm::{
-	IsPrecompileResult, Precompile, PrecompileHandle, PrecompileResult, PrecompileSet,
+    IsPrecompileResult, Precompile, PrecompileHandle, PrecompileResult, PrecompileSet,
 };
 use sp_core::H160;
 use sp_std::marker::PhantomData;
@@ -12,50 +12,50 @@ pub struct FrontierPrecompiles<R>(PhantomData<R>);
 
 impl<R> FrontierPrecompiles<R>
 where
-	R: pallet_evm::Config,
+    R: pallet_evm::Config,
 {
-	pub fn new() -> Self {
-		Self(Default::default())
-	}
-	pub fn used_addresses() -> [H160; 7] {
-		[
-			hash(1),
-			hash(2),
-			hash(3),
-			hash(4),
-			hash(5),
-			hash(1024),
-			hash(1025),
-		]
-	}
+    pub fn new() -> Self {
+        Self(Default::default())
+    }
+    pub fn used_addresses() -> [H160; 7] {
+        [
+            hash(1),
+            hash(2),
+            hash(3),
+            hash(4),
+            hash(5),
+            hash(1024),
+            hash(1025),
+        ]
+    }
 }
 impl<R> PrecompileSet for FrontierPrecompiles<R>
 where
-	R: pallet_evm::Config,
+    R: pallet_evm::Config,
 {
-	fn execute(&self, handle: &mut impl PrecompileHandle) -> Option<PrecompileResult> {
-		match handle.code_address() {
-			// Ethereum precompiles :
-			a if a == hash(1) => Some(ECRecover::execute(handle)),
-			a if a == hash(2) => Some(Sha256::execute(handle)),
-			a if a == hash(3) => Some(Ripemd160::execute(handle)),
-			a if a == hash(4) => Some(Identity::execute(handle)),
-			a if a == hash(5) => Some(Modexp::execute(handle)),
-			// Non-Frontier specific nor Ethereum precompiles :
-			a if a == hash(1024) => Some(Sha3FIPS256::execute(handle)),
-			a if a == hash(1025) => Some(ECRecoverPublicKey::execute(handle)),
-			_ => None,
-		}
-	}
+    fn execute(&self, handle: &mut impl PrecompileHandle) -> Option<PrecompileResult> {
+        match handle.code_address() {
+            // Ethereum precompiles :
+            a if a == hash(1) => Some(ECRecover::execute(handle)),
+            a if a == hash(2) => Some(Sha256::execute(handle)),
+            a if a == hash(3) => Some(Ripemd160::execute(handle)),
+            a if a == hash(4) => Some(Identity::execute(handle)),
+            a if a == hash(5) => Some(Modexp::execute(handle)),
+            // Non-Frontier specific nor Ethereum precompiles :
+            a if a == hash(1024) => Some(Sha3FIPS256::execute(handle)),
+            a if a == hash(1025) => Some(ECRecoverPublicKey::execute(handle)),
+            _ => None,
+        }
+    }
 
-	fn is_precompile(&self, address: H160, _gas: u64) -> IsPrecompileResult {
-		IsPrecompileResult::Answer {
-			is_precompile: Self::used_addresses().contains(&address),
-			extra_cost: 0,
-		}
-	}
+    fn is_precompile(&self, address: H160, _gas: u64) -> IsPrecompileResult {
+        IsPrecompileResult::Answer {
+            is_precompile: Self::used_addresses().contains(&address),
+            extra_cost: 0,
+        }
+    }
 }
 
 fn hash(a: u64) -> H160 {
-	H160::from_low_u64_be(a)
+    H160::from_low_u64_be(a)
 }
